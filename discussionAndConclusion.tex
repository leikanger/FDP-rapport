
%TODO Skriv: Sett av 2 dager.

%//{








%XXX Bra, men veit ikkje kor:
% In SANN, every aspect of spatiotemporal effects are simulated.
% For example the delay caused by the transmission throught the axon, before a synaptic transmission.
% This is simulated in SANN, for example by having a serially linked list of elements of a timedelay of one time iteration each.
% When the axon element containing the synapse is performs its action, the synapse is scheduled for execution.
% 
% A different scheme was developed for the new model, based on how a node is scheduled for spiking in $\kappa$ANN.
% %This is the scheme that is the way a node is scheduled for spiking in $\kappa$ANN.
% %Another aspect that was developed for this project was the concept of time scheduling as done in $\kappa$ANN.
% In this concept, each node contains a variable giving its planned task time.
% When the function that iterates time is executed, it also compares the present time with each elements scheduled task time.
% At the right time, the node is executed.
% %When the time arrives, a pointer to the element is inserted into \emph{pWorkTaskQue}.
% 




% % TIL DISKURS:
%%XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
%Skrive at design av/teorien bak  de to impelmentasjonene er så forsjellig at det er vanskelig å sammenligne de to med testing. En enkel kjøring vil ha statisk input (ikkje-endrende input).
%Mealy varianten av SANN (KANN) er spesialisert for ANN med dynamisk (endrende) input. Vil gi eit vanskeligere testoppsett for sammenligning av de to. Lett å implementere for KANN, vanskeligere å implementere for SANN.
%(Da må eg ha egene sensor-neuron som er spesiallaga for å sense en slik dynamisk state).
%%XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX

%
% 	%FRA Design: (er med i ferdig tekst)
 	%The new model will be named $\kappa$ANN, referring to the constant $\kappa$ in eq. \eqref{eqVerdiligninga}. The old model is often referred to as SANN.
 	%Initially, the two models were thorough to be so similar that each node element could be implemented as two variants of the same class.
	%To accomplish this, a scheme based on pointer functions and common variables was devised.

%	- Skriv om forbedring av estimert fyringstid: Kan bruke metoder fra kybb. F.eks. eit spesialisert kalman--filter kan kanskje utvikles?
	
% 					Høgere ordens estimasjon vil nok heilt sikkert gi bedre oppførsel. No er overføringa basert på en naiv estimering av fyringsfrekvens.



% XXX SKRIV OM planning of other tasks: (Teksten er med i resultat-og-diskurs: "comparison of the individual elements" : "The mechnisms of the auron element")
% 	As this implementation have been based on the SANN model, the \emph{K\_axon} also makes use of the \emph{doTask()} function.
%	The alternative way of planning synaptic transmission and other planned tasks first became clear to the author durin the writing of this report, these aspects have not been implemented.
%	As the principle of task planning has been used for the auron element, and can easily be extended to be used for other elements, this is included in the discussion.
%	%The reasoning is sound, and the concept of estimated task time can easily be extended to synapses and other elements. Due to time constraints, this is unfortunately not implemented.




% Kva er nytt i denne oppgaven:
% 	- time planning: kanskje KANN modellen er mindre effektiv, men elementet med time planning kan brukes for SANN også. Da slepper vi å simulere time delay.
% 		Axon blir dermed unødvendige, og vi kan lage eit scheme som bruker tidsplanlegging for forskjellige tasks. FUNKER FOR BEGGE MODELLER!
%
%
%//}

\section{Final Discussion and Concluding Remarks}
In this project, a new model for ANN has been developed.
As the primary focus is to compare the developed model to the other model capable of representing spikes for the nodes, the new model is designed strongly inspired by SANN.
Perhaps to strongly inspired.
%In the course of this project what is thought to be a new model for artificial neural networks have been developed. 
%Because the primary focus of the project was to compare the developed model for ANN with other ANNs with the ability to represent both firing time and firing frequency, the development and implementation recieved this focus. 
% %The new model was therefore initially implemented as a mere variant of a third generation ANN, with respect to information propatation.
%Because such a model could not be found, $\kappa$ANN was compared with the model capable of representing firing time, SANN.

To make the two models comparable, the new model was initially designed to be as similar to SANN as possible.
This caused the two implementations to be to similar, and the true merits of $\kappa$ANN were unused.
Due to the comparable inheritance--design, it was possible to alter the $\kappa$ANN design, on the level of the node's subelements. %, and the $\kappa$ANN model was redesigned.
As every aspect that required a different design was changed and implemented separately from the SANN implementation, the differences between the models became prominent.

The activity variable of the two models differ.
For the SANN model, it is the instantaneous value of the node that is in focus.
When this level of this value goes above threshold, the node fires.
As the node fires when the value reaches threshold, we could say that this is a reactive model of firing.
The output of the node is given as a reaction to the state of the node.

For $\kappa$ANN, we have a transmission of the summed input of the node. 
This is the same scheme as for the second generation ANN. The output varies as a result of the input.
In addition, $\kappa$ANN makes it possible for each node to compute the firing time.
As timing is important in both computation and stability of synaptic plasticity, this gives a tremendous advantage to $\kappa$ANN in comparison with the second generation ANN.
It also enables the $\kappa$ANN node to give output directly to any node based on the SANN model.

When transduction mechnisms for $\kappa$ANN is developed, the transduction nodes can evaluate spiking input and get the corresponding $\kappa$. % from the spiking input.
As the node gives output to $\kappa$Ns, we have ``translated'' the signal from being in the SANN model of synaptic transmission to the $\kappa$ANN model.

%We get that it is possible to give input to a $\kappa$ANN node 
This makes it possible to send input to a $\kappa$ANN node from both of these models. 
The first generation ANN is not used much, it is possible to make such transduction mechnisms to nodes of the first generation as well.
This gives that $\kappa$ANN might show important as a link between networks of different models.

There is also a difference in the mechanisms of the input, for the SANN model and the $\kappa$ANN model.
The SANN model integrates the input over time, while the $\kappa$ANN model use a state that gives it's activation level.
The activation \emph{level} is thus a result of the transmission in $\kappa$ANN, and a result of the \emph{level} of synaptic tranmsissions in SANN.

%For SANN, the activation \emph{level} is a result of the level of input transmissions.
Let us take a look at a simplified example where all synapses have the same constant synaptic weight.
The activation level of the node, often represented by the firing frequency of the node, is given by the rate of input transmissions.
All these input transmissions have to be executed for the SANN node.
For the node to have a large level of activation, the frequency of this input has to be large, and the simulation is computationally demanding.
The \emph{change} of level of input does not need an own computation for compute the effect of, in SANN
%TODO
% Oppsummere: KANN: input gir activation level. SANN: 
% i tillegg har vi at SANN beregner en gang per input, mens KANN gjør det en gang per iter.

For $\kappa$ANN, what is transmitted between the nodes is the presynaptic activation level.
This gives the level of activation for the postsynaptic node.
As $\kappa$ is time--invariant, computation of the effect of $\kappa$ is only nessecary when the input level is changed by a synaptic input.
The activity of $\kappa$ANN, for example the calculations of a node's spike, is computed when $\kappa$ changes.
For a constant level of input we therefore have that no calculations are needed, and the next spike can be planned one period later (the period is one of the calculated varies).
The only conputational cost for the node is therefore the action of signalling a spike to its output synapses.

As a result of this discussion, we have discovered a fundamental difference between $\kappa$ANN and SANN in respect to efficiancy.
%For situations of a high activity level, $\kappa$ANN will not be affected by this while SANN will get an increase of the computational load propotional to the activity level.
$\kappa$ANN will not be affected by a high activation level, while SANN will get an increase of the computational load propotional to the activity level.
For situations of a high \emph{rate of change} for the activity level, SANN will be unaffected while $\kappa$ANN will get an increase of workload  propotional to the number of time iterations where $\kappa$ is changed.
Note that as $\kappa$ANN only calculates the result of a transmission after the current iteration, only the integer period between a change in $\kappa$ will affect the system.
For large networks of a high connectivity, the probability of \emph{not} recieving a signal for a time iteration is very small. 
We can therefore state that $\kappa$ANN will have a constant work load, uncorrelated with the activity level of the network.
This is a very important result.
If the efficiancy of $\kappa$ANN is of the same scale as that of SANN, $\kappa$ANN will be a large contribution to the use of ANN with a spiking capability.

%Efficiancy was not tested in this project. The behavior of single nodes was, and it was compared on elements that SANN was able to provide.
Only the behavior of the single node was compared, not the efficiancy of a network of nodes. 
This is due to time constraints and the size of this project.
As the comparison was based on aspects both models was capable of, the comparison was done on the pemises of SANN.
%The comparison was therefore done at the premises of SANN. 
Fig. \ref{figComparisonBetweenSsensorAndKsensorDepolCurveFIXEdError} shows that the behavior of the value is the same for nodes of the two models.
%The next step shold therefore be to compare the two models with respect to efficiancy.

%//{
% If we define the third generation ANN as a network of nodes capable of firing a spike as the result of past and present input, $\kappa$ANN could fall under this category.
% %An implementation where the output of a node is given as a spike following an imput history that cause the value of the node to go to suprathreshold levels, the implementation would fall under the previous definition of SANN.
% %The nodes of this implementation of $\kappa$ANN could be said to be a Mealey automata of the LIF model of the neuron, and could therefore give output to a SN. %SANN model. %BLI HEILT SIKKER PÅ MEALY AUTOMATA! TODO
% % % % % 
% If the third generation ANN is defined as a network of nodes where the activity is propagated by spikes, $\kappa$ANN would not belong to this category.
% 
% In this implementation, the time of propagation also differs from that of the SANN model. 
% It was found best to propagate $\kappa$ ``immediately'', that is the time iteration after the time of the changed $\kappa$.
% Initially the propataion of the activity level waited until the first spike of the node. This gave unrealistic time delays in the network.
%//}

%//{ Kommentert ut : Propagation 
%It was found that the time delay introduced by waiting for the first spike gave a delay thought  to be to large. In this implementation the activity of the node propagates as soon as the input value changes.
% %
% %The $\kappa$N could also give output as a function of the only its input. 
% % TODO TODO Få med at neste setning bare gjelder "in respect to the output .."
% If the node propagates its signal ``immediately'', it could be seen as stateless with respect to its output. %, and becomes a variant of the second generation ANN for this aspect of the output. %XXX sjå over setn. Spess siste 5 ord.
% The output then becomes a variant of the output given by a node of the second generation ANN.
% % 		% 		%
% The activation function is based on a mechanistic model of the neuron, and differs somewhat to that of a node of a second generation ANN.
% %If we instead let each $\kappa$N give an output as a function of the present and estimated future input, and give a similar output, the network becomes something else.
% %The output now varies as a function of the input, and the node becomes could be made stateless in this respect. 
% %In this case the ANN nodes become very similar to a node of a second generation ANN.
% As output of a node is given by the activity level of the node, not the state of the node, we have that a $\kappa$ANN is able to communicate with an ANN of the second generation.
% % XXX Få også med at i tillegg har den mulighet for å gi anna type output. Til SANN, som spikes..
% 
% We also have the oppurtunity to calculate the ``depolarization'' value of the nodes by the concept of ``time windows''. 
% %We still have the oppurtunity to calculate the value of the nodes by the concept of ``time windows''.
% % TODO Skriv at vi kan kalkulere spike times.
% By equations developed for this project, the $\kappa$N also has the ability to calculate the time of its next spike.
% By making specialized synapses for this purpose, a $\kappa$N could therefore communicate with a node of the third generation ANN, SANN.
% %By making specialized synapses for this purpose, a $\kappa$N could also communicate with a node of the third generation ANN, SANN.
% To achieve this, a special synapse based on the SANN synapse has to be developed for the conjunction of a KN and a SN.
% %To achieve this, a special synapse based on the SANN synapse has to be developed for the connection between a KN and SN.
% This synapse should then be based on the synapse used in the SANN model, where only the spike is transmitted.
% %If this synapse is created by the model used for the SANN synapse, where only the spike is transmitted, nodes of the $\kappa$ANN model is able to communicate with a SANN node.  %makes it possible 
% 
% %If desired, the spike time and state of the neuron can still be calculated. 

%TODO Skriv vidare her..
% TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO 
%Fortsett litt, her. Tenker at det neste kan stå sist..

% //}}





%PÅ slutten: 

In this project, a new model for simulating time delay is proposed.
%If each element of the simulated neuron contains a variable that gives its execution time, the scheduler function responsible for iteration of time
This model of sheduled task times is based on that each element contains a variable that gives the time of the next planned task.
If this list is compared to the next time iteration by the time--iteration function, this function could also execute the task at its planned time.
This aspect is not model--specific, and can be used for both models, but as such mechanisms are native in $\kappa$ANN, it is best incoorporated in the $\kappa$ANN model.

As all aspects used in the design and implementation in this project is designed by the author, time limitations made it impossible to commence a thought literature search to find if an aspect allready has been developed.
It is therefore unknown to the author whether the mentioned aspects are contributions, or just ``reinventing the wheel''.
For the new model, however, we can be fairly certain.
%About a month was spent searching for similar models,
After a comprehensive literature search, and lengthy discussions with professor Yasser Roudi, it was concluded that this is the first ANN model of its kind.









% //{ En liten gave til Master-Per (meg om eit halvår eller år): 	over ei side med bra tekst..
%
%\section{Discussion 2. Denne skal nok vekk.}
% 
% % TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO 
% % DETTE er ikkje diskussjon. Dette er implementasjon eller noke.      TODO FLYTT TIL design-kapittel. Siste section: discussion (eller noke)
% % TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO 
% 
% %En eller anna plass: (ikkje akkurat her) Skriver her fordi eg har inspirasjon no, og ikkje vil leite..) 	Ja! Kanskje i "conclutions"XXX
% Implementing the mechanisms of a neural simulator is not trivial, even without optimizing it for run time efficiency.
% %todo SKriv om neste linje! xxx
% Even if this is not an important aspect of this project I have tried to, wherever possible, optimize the implementation for efficiency.
% %Skrive kvifor: Om at designet er optimalisert både for generalitet (for å gjøre utvidelser/endring lettere) og for effektivitet. DETTE for å kunne bruke implementationen videre (personlig, eller for andre).
% 
% The functions that are most often called are inlined. This means that I have given a hint to the compiler to put the compiled code wherever the functions are called.
% This causes the function calls to run faster but also increases the size of the executable file, so this should be used with caution. %Kanskje skrive dette, men også da skrive størrelse på endelig program. ca. 0.5 M (?)
% For this implementation, size will not be a problem. %Kvifor?
% Inlining of functions are still kept to a minimum, in case of further work on this software. %skriv annaleis. Kvifor "in case of further work on this software."? Forklar bedre, eller skriv om (anna argumentering).
% 
% Also in other parts of the implementation, the code is written with a focus on possible future expantion.
% %Difor er ting laga enkel å forstå for en som kan nevro: oppsettet av nodene er lagt opp som det biologiske neuronet.
% The object model is designed to be general for the two models, both to make the two implementations more comparable for this project and to make the implementation better suitable for future comparison.
% 
% The design of each node is based on the biological neuron to be more intuitive for programmers with knowledge of neuroscience. 
% This is not only to make the implementation easier to use for potential future programmers, but also because little is known about what is important in neuroscience.
% If the implementation is constructed strongly inspired by the emulated system, with multible elements constructed in the same way as the original system, expantion and modification of the individual elements involve less effort.
% Say, for example, that new aspects are discovered tomorrow. In this case, the code can easier be modified after this discovery.
% 
% This principle does not only account for future uses by other programmers.
% In multiple occations, aspects that are where new to me have been implemented at after the main functionality of the classes where designed. 
% This required less work because I followed principles that was important to Bjarne Stroustrup during the creation of C++; To make the design general and open and suited for any future uses.%ELLER NOKE Siter"TheDesignAndEvolution of C++".
% 
% 
% % TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO 
% % dette ER diskurs (?) :
% One element that is not implemented, is axo--somatic and axo--axonic synases. 
% This is synapses where the input to the postsynaptic neuron enters at other places of the neuron than the dendrite. 
% In biology, most inhibitory synases have theire input close to the soma of the postsynaptic neuron. 
% This will give the inhibitory input less delay compared to the excitatory input, and might be an important aspect in neural computations.
% This can be implemented easily if this is found to be important for some future use of this code.
% 
% Another important aspect that is not impelented is axo-axonic synapses, linked to short term synaptic plasticity.
% %XXX An axo--axonic synapse is a synase that enters the postsynaptic neuron somewhere close to one of its output synapses.
% % Gjør om rekkefølgen litt. Skriv om short-term syn.p. først, så evt. axo-axonic synapses.
% Short--term synaptic plasticity is synaptic plasticity that does not have any long term effect of the neuroal network (learning), only on more immedate aspects of signal transmission.
% In particular, we have the synapses that gives input near the axon terminal of the neuron (axo-axonic synapses). This will alter the depolarization at the neurons output synapses. %og auke/minke mengde Ca2+ i presyn. bit av synapsen.
% This will not cause any transmission to occur, only ``prime'' the presynaptic membrane of the synapse for transmission.
% When the next action potential arrives, the size of the transmission will be larger than usual (or less, depending on whether the axo--axonic synapse is excitatory or inhibitory).
% Again, neither short--term synaptic plasticity or axo--axonic synapses has been implemented because this was not an aspect of this project and due to time constraints.
% % Skriv heller at short--term syn.p. ikkje er implementert, så axo-axonic synapses ville ikkje auka funksjonaliteten til simulatoren.
% Implementing it will involve less work due to the implementation design in this code.
% % Denne setninga er for å vise at det er lett å innføre. Skriv om.
% 
% If the goal of the implementation is to simulate a neural network from biology, spatial and temporal resolution is more important than efficiency of the calculation.
% %When it comes to temporal and spatial resolution, this can easily be extended.
% In this implementation, spatial and temporal resolution can easity be extended.
% If we want to increase the accuracy, this can be done by increasing the number of elements in each node (and making the time step accordingly smaller).
% This will also make the computational efficiency of the simulator less, and the pragmatic use of the simulator will suffer.
% 
% If we need a better accuracy, and for example double the number of serial elements in each node and halve the size of the time step, the functioning of each element will be the same.
% The temporal and spatial resolution will be increased two-fold at the expence of the computational efficiency of the simulator.
% 
% With ``spatial resolution'' i refer to the ability to separate between elements located at different positions in space.
% This is important for the output, scince different output synapses are situated at different locations of the neurons axon.
% This will cause different transmission delays, and might be important for the neural calculations.
% % Also the axon will be have more elements, and different synapses along the axon may have differenti time delay.
% This gives us the ability to make a separation between ``early synapses'' and ``late synapses'' along the axon, and gives us a better spatial resolution for the simulated neuron.
% 
% The whole reason for developing the third generation ANN, spiking artificial neural networks, was the growing focus on the timing of the different events within the neural network.
% This is computational demanding, and high resolution simulations is not suited for real time pragmatic uses of ANNs. For simulations used to test hypothesis in neural science, however, accuracy is most important.
% The focus on generality in this implementation will therefore make the code reusable for possible future pragmatic uses and for implementing neural simulators.
% 
% If the new model is more effective than the old model for spiking neural networks, we can not know whether this is only goes for one of these uses. 
% For this reason I found it best to implement as generally as possible, for future efficiancy comparison between the two models.
% %Skrive eksempel: "More specifically, if we divide the axon into smaller pieces, spatial accuracy is better."
% %Skriv om forskjellane mellom KANN og SANN. Her kommer kanskje største fordelen med KANN? (Kan kanskje legge inn vilkårlig antall element, til tilsvarende størrelse på 'time step').
% 
% %slutt: En eller anna plass: ....



%//}





\section{Directions for Further Work}
% Fekk ikkje gjort: 
	%\subsection{Analysis of the postsynaptic activity variable as a result of syn. transmission} % KANSKJE
This work is a comparison between the signal propagation mechanisms of SANN and $\kappa$ANN.
As time dictated, synaptic plastity was not implemented and compared.
Synaptic plasticity is an active research topic both in the field of ANN and in neuroscience, and established formal methods are hard to find.
% % 
%The study of the effect of synaptic plasticity, in respect to the mechanisms of $\kappa$ANN is one direction worth taking. %XXX Skriv om!
The study of the effect of synaptic plasticity, in respect to the mechanisms of $\kappa$ANN is a direction that needs further recearch.

% //{ om Axo-axonic synapses
% %XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXx Bra tekst. Ta med!
% One element that is not implemented, is axo--somatic and axo--axonic synases. 
% This is synapses where the input to the postsynaptic neuron enters at other places of the neuron than the dendrite. 
% In biology, most inhibitory synases have theire input close to the soma of the postsynaptic neuron. 
% This will give the inhibitory input less delay compared to the excitatory input, and might be an important aspect in neural computations.
% This can be implemented easily if this is found to be important for some future use of this code.
% 
% Another important aspect that is not impelented is axo-axonic synapses, linked to short term synaptic plasticity.
% %XXX An axo--axonic synapse is a synase that enters the postsynaptic neuron somewhere close to one of its output synapses.
% % Gjør om rekkefølgen litt. Skriv om short-term syn.p. først, så evt. axo-axonic synapses.
% Short--term synaptic plasticity is synaptic plasticity that does not have any long term effect of the neuroal network (learning), only on more immedate aspects of signal transmission.
% In particular, we have the synapses that gives input near the axon terminal of the neuron (axo-axonic synapses). This will alter the depolarization at the neurons output synapses. %og auke/minke mengde Ca2+ i presyn. bit av synapsen.
% This will not cause any transmission to occur, only ``prime'' the presynaptic membrane of the synapse for transmission.
% When the next action potential arrives, the size of the transmission will be larger than usual (or less, depending on whether the axo--axonic synapse is excitatory or inhibitory).
% Again, neither short--term synaptic plasticity or axo--axonic synapses has been implemented because this was not an aspect of this project and due to time constraints.
% % Skriv heller at short--term syn.p. ikkje er implementert, så axo-axonic synapses ville ikkje auka funksjonaliteten til simulatoren.
% Implementing it will involve less work due to the implementation design in this code.
% % Denne setninga er for å vise at det er lett å innføre. Skriv om.
% %XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXx
% //}

Most conclusions in this report are theoretical. 
One of the aspects that is theorized is that for certain situations for the single node, $\kappa$ANN will be more effective than SANN.
Because of the complexity of the single node, and even more for networks of such nodes, it is very had to find theoretical results in respect to efficiancy.
The rightfullness of these results should therefore be found experimentally.

Espessially when synaptic plasticity is implemented, the efficiancy of $\kappa$ANN is hard to predict.
Synaptic plasticity causes the input of the nodes to change, and $\kappa$ would change each time iteration.
The fact that the effecs of a changed $\kappa$, is at most computed once every time iteration makes it possible that $\kappa$ANN still is more effective than SANN.
%Even if $\kappa$ANN shows to be less effective, we still have the concept with a more stable computational load for the simulation.
This becomes important if an ANN with spiking capabilities is to be used in technology, and should be researched further.


%The inital desire to develop this ANN model was that simulation of a time--variant variable used to much computational resouces.

%In this implementation, it is possible that the full advantage of the new model is neglected in the desire to compare the model to the SANN model.
%Because some of these aspects was first discovered when the results were analyzed, this should be the first continuation of this project.			%this will be placed under "for furter work".



	% Tatt vekk fra teksten et annet sted. Passa ikkje der, men viktig å ha med! (brukes seinare i konklusjon)
As the $\kappa$N is designed with a special focus on spike timing, it is also possible to communicate with a node of the third generation.
	% TA VEKK: Interfacing with a node of the first XXX Dersom eg ikkje HEILT forstår 1.gen. noder.
For interfacing with a node of the first or third generation ANN, the spike time of the node will be used. % ref_123@i_KANN TODO enten forstå 1.gen HEILT, eller ta bort dette. (her og over("..all other gen. ANN"))
As the node ``fires an acion potential'', and sends output thourgh all its output synapses at the time calculated by eq. \eqref{eqRemainderOfPeriod}, the node could work as an interface to a node of a third generation ANN. 
The connections between the $\kappa$N and the SN will use the transmission scheme from SANN, where the synapse transmit its synaptic weight to the postsynaptic node. 
Transmissons from the SN to  the $\kappa$N is a little more complex. Here the equivalent $\kappa$ resulting in the level of transmission needs to be calculated, and from this the level of transmission.
Development of a transductor node between different generations of ANN will not be procecuted further, but is an important direction to take.
This will therefore be recommended for further research.
%This is an important direction for further work, as an interface between the second and third generation ANN makes it possible to use aspects from both models in technology.

%//{
% Effektivitetsanalyse.
% XXX Syn P
%    Eit element eg ønskr sterkt å gjnnomføre er å sammenligne effektivten til den nye modellen til andre modeller. Eg føler modellen har store muligheter for effektivitet, spesiellt for neuralkretser med der nodenes $\kappa$ er konstant.

%\section{Effektivitetsanalyse: Korleis gjennomføre}
%Kan lage ei while-løkke, som lager eit nytt neuron i kvar iter, og lager synapse til eit E neuron.
%
%Slik kan eg lage eit testneuron med f.eks. 1000 input (kan referere til at dette er estimerte vanlige nivået).
%Kan dermed sammenligne SN og KN med hensyn på effektivitet.
%
%Dersom eg vidare lar sensor funk variere kvar tiande tidssteg for ti prosent, 20. tidssteg for 20 % osv.
%Så har eg noke å skrive om i forhold til testoppsett.
%


% 	- Innføre dynamisk teskel (bedre modell for refraction time)
% 	- Utvikle KANN for seg selv. Slik at dette blir så effektivt som mulig..
% 		- Foreta effektivitetsanalyse.
% 	- Lage transduction mellom KN og SN. Også mellom fN og KN. Kanskje heile veien, mellom alle generasjoner ANN.
% 	- single compartment implemention of multiple compartment model of the neuron. (KANN, time scheduling, planlegging av tasks)


%\section{Om transdution mellom 2g og 3g ANN}








% \section{Concluding Remarks}
% 
% To make the two models comparable, the new model was initially designed to be as similar to SANN as possible.
% In regard to signal propagation, this caused the design to be a mere variant of SANN;
% 	The activity of the node propagated when the computed value of the node went to suprathreshold levels.
% %This caused the implementation of $\kappa$ANN to be a mere variand of SANN, with respect to information propagation;
% %	The activity of the node propagated when the calculated value of the node went to suprathreshold levels.
% % %When the model was futher developed, it became clear that  %TODO Skriv når, og kvifor(at da) kappa propagerer.
% 
% As the equations evolved, the aspect of planned events was introduced in the model.
% The node no longer transmitted as a result of the level of the value, it could plan its actions in advance.
% To be able to do this, 
% This gave a postsynaptic node the capability to 
% The firing time no longer happened reactively to the value going to suprathreshold levels, it planned the time of firing, and propagated a variable propotional to the node's firing frequency.
% //}

%fortsett med det under.



% \section{Summary}
% In this project, a novel model for artificial neural networks has been developed. 
% A special emphasis has been put on the ability to represent the spike timing of the nodes, both in the design of the new model and in the comparison with ANN models of earlier generations.
% 
% % TODO TODO Fortsett her. Neste (grønn tekst) er litt kiip. Vidare er bedre, føler eg.
% 
% %As the value reaches the firing threshold, the neuron will fire a simulated action potential and reset its value.
% %Equations was set up for calculating when the value of the node goes above this threshold, and from this equations of the inter--spike period of the neuron.
% %
% %The novel model, named $\kappa$ANN, was based on mathematics developed during this project.
% %As the neuron often is modeled as a leaky integrate--and--fire 
% %where elements from technical cybernetics.
% 
% 
% The novel model for a neural network with the ability to represent spike timing was developed by the use of mathemathics from the field of technical cybernetics.
% During the project, it was found that these equations gave larger capabilities than the SANN model. % more than the ability to find the value of the node.
% Given a constant level of input, equations are developed for calculating the future values and firing time of each node, and the time of the next spike is possible to estimate.
% The simulated depolarization value of a node of the new model has been compared with the value of a node based on the SANN model.
% The time course of the value is compared for a continuously changing input level.
% It is concluded that the transient value curve of the new model is as good as, or perhaps a little better than the direct simulation carried out by the SANN model.
% %Given a constant level of input, equations are developed for calculating the future values and firing time of each node.
% %
% 
% The equations are based on the time--course of a leaky integrator to model the LIF neuron, and makes it possible to calculate future values it the input stays constant.
% % These equations gives the oppurtunity to calculate the future values, and thus estimate the firing time of the neuron. %, also the future values of the value can be computed based on a constant input.
% % This further gives the oppurtunity to estimate the firing time of the node.
% % 
% % As the equations are based on a constant level of input, the concept of a ``time window'' is devised.
% % By the use of this concept and equations developed espescially for this purpose, it is found that the next spike time of a node can be calculated if the initial value and level of input is know for the time window. %Dårlig slutt.
% % 
% % By the use of these methods, an ANN is developed, and compared with the SANN model. % XXX ... theoretically AND EXPERIMENTALLY with the ... ?
% % % % %
% % The two designs are implemented, and the behavior of the node is compared.
% % % KANSKJE: TA VEKK? Skal bare være på ei halv side, og nevne de aller viktigaste funn..
% % %
% % %The comparison of the transient time course shows that the new model gives a similar simulation of the value.
% % %There is a very small difference, and it is discussed 
% % The transient time course of the value differs with a very small amount, and it is discussed whether this difference is an error caused by the global truncation error in the SANN node.
%  
%  
% As the new model is based on the concept of the spiking neuron, spike time can be calculated for a $\kappa$N.
% It is therefore possible to transmit spikes through specialized synapses, and nodes of the $\kappa$ANN model can communicate with nodes based on the SANN model.
% %Transduction of the output of the $\kappa$N to a SANN will probably involve less effort than the transduction the other way.
% As the usual output of a $\kappa$N is given by an ``instantaneous frequency'' calculated from the present $\kappa$, the $\kappa$ANN node is able to communicate with nodes of the second generation ANN.
% The activation function for $\kappa$ANN can be seen as an activation funtion based on a mechanistic model of the neuron.
% % %
% It is therefore possible to use $\kappa$ANN as a interface between the second and the third generation ANN.
 
 % TODO Skriv om effektivitet, mulighet for å rekalkulere kappa,   ,    ,    ,    , 
 % TODO OTOD TODO Fortsett her, etter at sammenligninga er gjort.
 
 %An ANN is designed by using these equations, and compared with a design based on a direct simulation of the neuron.
 % %The former design, known as SANN, 
 %The concept of the ``time window'' was developed to establish time intervals where the time window is defined to be a period where the input is constant.
 %Based on this consept, and equations developed especially for this purpose, it is possible to update the value of the node each time the input level of the node changes.
 %
 %In this report the capability of these two consepts combined is illustrated by comparing the value of a node of the new model with a node based on direct simulation of the neuron.
 %The value of the nodes of the two models is compared, and it is concluded that the transient time course of the new model gives a time course that is at least as good as the direct simulation done by the SANN model.
 %
 %It is concluded 
 %The time course of the value of the two nodes are compared 
 %The two the time course of the value of a node of the new model ANN with the time course of the previous model with spiking abilities.
 %Appearently, the two curves follow eachother.
 %A closer analysis gives that there was a small difference between the two.
 %This error it thought to be based on the concept of a global trunction error for the SANN caluclation of %HER XXX
 %After a closer analysis, it was found that the two cuves have a little 
 %It was concluded that the two values follow
 %It was concluded that the difference between the two plots gave maximum difference
 %it was possible to design and implement an artificial neural network based on the mathemathics developed.
 
 
 
 
 
 
 
 
 
 
 % //{
 % % TODO TTTOOOODDDDDOOOOOO :  Fra [\label{ssecTheGeneralDesign}]  : This text will later mention some possible examples of this.  		Få det med i diskurs!
 % 
 % 
 % 	% TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO 
 % 	%For distributed computing, the taskscheduler function could be avoided by letting each subelement execute the small piece of code from \emph{taskscheduler()} before it returns.
 % 	%Centralized command over the network could then be avoided, and if %skriv om at time-skille-elementet kunne kjørt broadcast av ny tid ved iterasjon.
 % 	% 	%For execution over network or other distributed executions could be performed by letting each subelement execute the code from \emph{taskSchedulerFunction()} before it returns.
 % 	%This would make the execution truly distributed. %Sterke utsagn! Kanskje eg skal begrunne dei meir?
 % 	% TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO 
 % 
 % % FInal remark: (gjelder pWorkTaskQue, \ref -> time propagation.
 % % TODO Lag en heil section som diskuterer bruk i distribuerte systemer: Fett for kappa..
 % 	For further development, we could let the the two listed function calls be included in the individual elements' \emph{doTask()} function. 
 % 	Before the funtion is completed, the two operations listed below could be executed before the function return.
 % 	This makes the design intrinsically distributed.
 % 
 % 
 % 
 % 
 % //} 



% //{
% Skriv at:
% 	- 1. gen. ANN er stateless, men overfører boolst signal. (det er i tidsdomenet)
%  	- 2. gen. ANN er stateless, men i frekvensdomenet. Dette er rettere.
% 	- 3. gen. ANN er med state. Dette er også i tidsdomenet, så får med temporale effekter.
% TENKING: KANN er med med state, og tidsdomenet. 
% 	For KANN varierer output med input også, og kan sees på som en mealey variant av SANN. 
% 	Dersom vi definerer 3.gen. ANN som eit ANN der output ikkje varierer med input, vil ikkje KANN tilhøre 3.gen. ANN.
% 		- Det er mulig å hente ut informasjon om tid, dersom ønskelig (til f.eks. syn.p.), men ikkje naudsynt.
% 		- Trenger ikkje beregne neuralnettet som eit SANN. Dette har vore gjordt i denne rapporten, men trengs ikkje.
% 		- Skrive i denne sammenhengen (kanskje i resultat?) at i løpet av denne oppgaven har hovedfokus vore på sammenligninig. 
% 		- Siden modellen ikkje var ferdig før prosjektet, gjorde dette at implementasjonen ble spesialisert for sammenligning (brukte spiking variantav synaptisk transmissjon). Dette er antaglig ikkje optimalt.
%Kanskje lage tabell, eller begin{itemize} her, under:
% //}







%//{
% Hugs modellen om syn.trans.  	Skriv i conclusion that a better model can be included with a greater ease, in the K-synaptic transmission than the s-synaptic t.
% 	(if I manage to modell such behavior..)


% Diskurs:
% 	- diskuter tid: de fleste neuron med realistisk mengde input vil ha en input per tidsiter. Dette gir at de antagligvis MAKS får eit input per andre iter (dersom alle fyrer maksrate..)
% 		Også da vil det bli meir effektiv modell for tid, men virkelige nytten kommer nok med KANN: da kan vi nok ha 'abituary size' på tidssteget (vil ikkje innføre meir belastning (FOR STATISKE NETT(nett med statisk aktivitetsnivå)) )
% 		JEJE..
%
% 	- avviket mellom SN og KN etter synapse når synapse var skjempestor   (nei: dette er resultat og comparison= 
% 
% 

% Conclution
% 	- i dette prosjektet har neuronet blitt simulert. To simulatore er skrevet. For å gjøre dette, har eg lest meg opp på det neurale systemet.
% //}

% //{
% Fekk ikkje gjort: 
	%\subsection{Analysis of the postsynaptic activity variable as a result of syn. transmission} % KANSKJE

% xxx skrive at det er bra med tidsinvariant overføring: Bl.a. kappa kan når som helst bli rekalkulert. Dersom ligninger for det blir utvikla, kan også kanskje v_0 bli rekalulert?

% XXX CONCLUSION : Eg har funnet at det er veldig bra å bruke Kappa som mål på aktivitetsnivå til neuronet. Dette kan være nyttig for neuroscience..

% XXX CONKLUSJON : skrive at modene i SANN (etablerte modellen) er en Moore variant av det biologiske neuronet. KANN er en Mealy automata av neuronet, noke som gir andre muligheter. Drøft.

% XXX CONKLUSJON : For fANN brukes gjennomsnittsfrekvens over time step. For KANN brukes estimert frekvens for å gi syn. trans.
% 					I denne oppgaven var det ikkje fokus, men dersom en bedre oppførsel ønskes, kan vi la estimerting av frekvens (for syn.trans.) være basert på metoder lært i kyb.
% 					Høgere ordens estimasjon vil nok heilt sikkert gi bedre oppførsel. No er overføringa basert på en naiv estimering av fyringsfrekvens.

% XXX SKRIV OM planning of other tasks: (Teksten er med i resultat-og-diskurs: "comparison of the individual elements" : "The mechnisms of the auron element")
% 	As this implementation have been based on the SANN model, the \emph{K\_axon} also makes use of the \emph{doTask()} function.
%	The alternative way of planning synaptic transmission and other planned tasks first became clear to the author durin the writing of this report, these aspects have not been implemented.
%	As the principle of task planning has been used for the auron element, and can easily be extended to be used for other elements, this is included in the discussion.
%	%The reasoning is sound, and the concept of estimated task time can easily be extended to synapses and other elements. Due to time constraints, this is unfortunately not implemented.


% 	xxx Skriv grunnen til at eg ikkje har nokon uventede resultater: at dette i all hovedsak har vert en utviklingsprosess, og alle uventede resultater har blitt ordnet på undervegs.
% 		Eksemper på slike er den lange diskusjonen tidligere, om avviket mellom K_auron og s_auron. Dette ble fikset. Mye tid har dermed blitt brukt på dette prosjektet.

% 	TODO TODO Poengter at synaptic transmission matematikk er basert på 2.gen. ANN (mens mykje anna er basert på 3.g). Dette kan diskuteres frem og tilbake!


%TODO : Skriv at selv om vi ikkje har fått tid til å kjøre effektivitetssammenligning, så har vi funnet eit viktig resultat. KN kan brukes til å oversette mellom 2.gen og 3.gen ANN.
% 		TODO Finn ut korleis 1.gen funker, og skriv evt. inn dette også. (sjå % ref_123@i_KANN i implementasjon_KANN.tex) EVT ikkje nevn "each of the other generation ANN" og "first gen. ANN" fra linja "% ref_123@i_KANN" står på.

% Kva er nytt i denne oppgaven:
% 	- time planning: kanskje KANN modellen er mindre effektiv, men elementet med time planning kan brukes for SANN også. Da slepper vi å simulere time delay.
% 		Axon blir dermed unødvendige, og vi kan lage eit scheme som bruker tidsplanlegging for forskjellige tasks. FUNKER FOR BEGGE MODELLER!
%
%


% Videre arbeid:
% 	- Lage syn. p.
% 	- Innføre dynamisk teskel (bedre modell for refraction time)
% 	- Foreta effektivitetsanalyse.
% 	- Lage transduction mellom KN og SN. Også mellom fN og KN. Kanskje heile veien, mellom alle generasjoner ANN.
% 	- Utvikle KANN for seg selv. Slik at dette blir så effektivt som mulig..
% 	- single compartment implemention of multiple compartment model of the neuron. (KANN, time scheduling, planlegging av tasks)
% 	- effektivitetsanalyse av dette.
%
%



% Oppsummering (conclution):
% 	innlede med kva som er  gjordt i dette prosjektet (gå gjennom kapittela og skriv ned..)
% 	- Skriv om transduction mellom ANN av ulike generasjoner. Kan bruke KANN til dette! (sjå sec \subsection{The Activity Variable} ).
% 	- Skriv at eg har gjordt den tidsvariante responsen til en overføring (at overføring skjer/ikkje skjer er avhengig av verdi før overføring. Dette skaper eit system som er avhengig av input-historie og tid(lekkasje).
% 		Om til: å ikkje lenger være tidsvariant. Kappa er på en måte tatt utafor tid. Kappa som overført variabel er ikkje tidsvariant, ikkje variant med andre variabler.
% 		=> Den tar vekk ulineariteten innført fra mekanismen: fyring!
%


% Feil/Mangler i denne sammenligninga:
% 	- Har ikkje sett på nettverkseffekta av tidspunkt for propagering av Kappa. Kan bli veldig rart at den propagerer "med en gang" (etter 'current' time iteration).
% 		%TODO analyser dette i diskurs!
% 	- Burde kanskje brukt meir tid på rapporten.
%
%
%
%
%

%%
%%XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
%Skrive at design av/teorien bak  de to impelmentasjonene er så forsjellig at det er vanskelig å sammenligne de to med testing. En enkel kjøring vil ha statisk input (ikkje-endrende input).
%Mealy varianten av SANN (KANN) er spesialisert for ANN med dynamisk (endrende) input. Vil gi eit vanskeligere testoppsett for sammenligning av de to. Lett å implementere for KANN, vanskeligere å implementere for SANN.
%(Da må eg ha egene sensor-neuron som er spesiallaga for å sense en slik dynamisk state).
%%XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
%
% //}




%\section{Discussion and concluding remarks}

%%Viktig eksempel til diskurs.
%		In addition, we have the aspect of \emph{how} the activity of the node changes. 
%		Let us take an example where we simulate a neuron with a constant level of synaptic input.
%		For the $\kappa$N, the node will have a constant activity level, and does not have to recalculate the firing time of the node when the node fires.
%		When the node fires, the node writes the current time iteration plus the previously calculated period to the member variable \emph{ulEstimatedTaskTime\_for\_object}.
%		When the estimated task time is the same as \emph{time\_class::ulTime}, the node fires again and the same is repeated.
%		For the SN, the number of input transmissions stays at a constant level to produce the same firing frequency for the node.
%		The number of actions for the SN will therefore stay at a constant level throughtout the simulated period.
%		As the $\kappa$N only has to calculate its activity level initially in the example, when its $\kappa$ is changed, we get a large difference in work load for this example. 
%		
%		The example is unrealistic for most circuits, but it examplifies when $\kappa$ANN will be more effective than SANN.
%		Even thought the example is unrealistic, there might me situations where a $\kappa$N would be better than a SN.
%% TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO 
%
%
%
%











%% XXX Ligger som conclusion:
%		\subsection{The Differences between the Models} %From a broader perspective / A larger view / Discussion : /  				XXX Skriv en av desse først..
%		From the previous section, the difference between the individual elements was discussed. 
% 		The elements was discussed one at a time, following the propagation of the signal in the biological neuron.
% 
% 		In this section, the results from the comparison will be discussed with a broader view.
% 		The differences in general design and implementation will be discussed first.
% 		We will also discuss what effect this might have on the efficiancy of the execution for each node.
% 
% 
% % KANSKJE DET HELLER ER CONCLUSION?
% %	\subsection{Discussion about the differences in the Elements} %TODO Endre tittel!
% 		As the SANN model is a direct simulation of each node's depolarization, SANN requires the design used in this project.
% 		For simulation of SANN, the design of each node should therefore be as introduced first in section \ref{secTheBiologicalNeuralSystem} about the biological neural system, 
% 			and later in sec. \ref{secDesignForANN} about the design of this implementation.
% 		In SANN, ach node executes the same actions as the biological equivalent.
% 		As the SANN model does not make use of planned actions, time delay is implemented as a direct result of tranmission through elements with a time delay of one iteration.
% 		Time delays spanning multiple time iterations can be implemented by having multiple elements in series.
% 
% 		%The alternative to implementing the  xxx skrive om single compartment model DERSOM TID.
% 
% 		In $\kappa$ANN, the firing time of each node is estimated by the present level of input. 
% 		When the time estimate is the same as the next time iteration, the element is inserted into \emph{pWorkTaskQue}.
% 		%As the $\kappa$N does not have to transmit only as a consequence of the firing time, the calculation of firing time could be limited to the nodes in use of the firing time of the node. 
% 		% % When synaptic plasticity is implemented, this for example includes every node with a simulated glutamatergic transmission (as the output synapses of these nodes will have STDP)
% 		
% 		In the $\kappa$N, time planning it therefore the mechanism behind the firing of a node.
% 		Delays caused by simulated intracellular effects could therefore be implemented by simply adding the time delay to the estimated task time.
% 		This is an effect that could be implemented for the individual synapse;
% 			When the node fires, all its output synapses' \emph{ulEstimatedTaskTime} variable is written over with the value [now]+[corresponding delay].
% 		This gives that the $\kappa$N could make use of a single compartment implementation without using a single compartment model of the neuron.
% 
% \subsection{TEMATISKE FORSKJELLER : skaper muligheter i forhold til effektivitet!}
% 		As this implementation have been based on the SANN model, the \emph{K\_axon} also makes use of the \emph{doTask()} function.
% 		In this implementation, the \emph{K\_auron::doTask()} only calls the memberfunction \emph{doTransmission()}. This could as easily be called by a central element, or not at all. %For synapsene kan legges direkte inn som planl. oppg
% 		The alternative way of planning synaptic transmission and other planned tasks first became clear to the author durin the writing of this report, these aspects have not been implemented.
% 		As the principle of task planning has been used for the auron element, and can easily be extended to be used for other elements, this is included in the discussion.
% 		%The reasoning is sound, and the concept of estimated task time can easily be extended to synapses and other elements. Due to time constraints, this is unfortunately not implemented.
% 
% 
% %fra auron: (tatt vekk derifra..)
% 		If the $\kappa$ANN is implemented by the 
% 
% %		As we could use the concept of task scheduling for different elements, simulation of intracellular propagation delay is unnecessary. %TODO TODO Skriv sammen med neste setning.
% %		As the concept a simulated delay is obsolete in $\kappa$ANN, we do not have to propagate the signal through the node.
% 																			% it is unnecessary to simulate the signal propagation throught the internal elements of the node.
% 		% Vi kan dermed bare endre ulEstimatedTaskTime_for_object til ut-syn. ved fyring!
% 		If the $\kappa$ANN is implemented by following this realization, we could use a one--compartment implementation for a multiple--compartment model of the neuron.
% 		%Among other improvements, the execution of the $\kappa$N could be done without the use of dereferencing pointers when variables are to be accessed.
% 
% 		In this case, the $\kappa$N is the only internal element of each node. The synapse is then percieved as the edge between two nodes in the graph.
% 		The $\kappa$N is therefore responsible for estimating the task time of every element of the node and its output synapses.
% %TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO 
% 		It is therefore responsen
% 		The $\kappa$N is then the only element in each node of the ANN, and is responcible to estimate task time for the auron and the output synapses.
% 		As this implementation used the SANN model as a basis, time delay is simulated by executing serial linked elements.
% 		This is unnecessary for $\kappa$ANN as it has the capability of time scheduling of tasks.
% 
% %		Examples of tasks that are to be executed after firing of the node is calculation of STDP of the node's synapses and transmission throught synapses going to output nodes of the SANN model.
% %		Neither of these aspects have not been implemented in this project, but the mechanisms used by the $\kappa$N is easily implemented.
% 
% 
% 
% 
% %% XXX TEMATISKE FORSKJELLER -- Når har vi høg load for systemet. Når kreves mykje ressurser?
% %	\subsection{Høgare ordens mekanismer som resultat av det over. Forskjeller..} 
% %	%Det kom fram at for KANN er det mulig å gjennomføre tidsdelay som kommer av axon og dendrite med bare auron-elementet.
% %	%Dette gjøres med å plusse på en på estimert fyringstid.. VIKTIG poeng!
% %	%
% %	% XXX Skriv om reactive vs. proactive kalkulering av fyringstid.
% %	\subsection{Design for each node, when designed as a simulation of temporal aspects of the neuron}
% %	% XXX Dette skal bare nevnes her (eller?), men skrives så utførende som teksten under, i egen section.
% %	% En annen ting en oppfatta var at simulering av kvart element ikkje var nødvendig for simulering av time--delay for propagering av AP: for KANN kan dette inkorporeres i estimering av fyringstid og periode (=>syn.transmitted var.)
% %	% 	For KANN kan man lett effektivisere bort simulering av tidsdelay, ved å bare legge til tidsdelayet i estimat av fyretid. Dette er vanskeligare å gjøre i SANN. I KANN er denne typen effektivisering "native".
% %	% 	Dette gir at for simulerings-likheten som er brukt i dette systemet (en dendrite, eit axon -- alle synapser samme plass..), så er det mulig med eit--elements noder for KANN uten å miste simuleringslikhet.
% %	% 		I implementasjonen er K_dendrite::doTask() og K_dendrite::doCalculations() definert til å gi sterk melding og avslutte programmet. Dette for å eksemplifisere at de ikkje er i bruk, og forsikre at de ikkje blir kalla.
% %	% 		For K_axon så gjelder fortsatt det at eg vil ha muligheten til å auke 'spatsio-temporal' oppløsning. Dette gjøres ved å legge inn fleire element av K_axon. K_axon blir dermed som eit navier--stokes kontrollvolum for neuronet.
% %	% 		Dersom en pragmatisk implementasjon blir laget fra denne koden, kan dermed K_axon fjærnes, of listen med output synapser og doTransmission() kan legges over i K_auron.
% %	% 		I såfall får vi eit enklere oppsett of kvar node, med bare eit node element (K_auron) og eit 'edge' element (K_synapse), uten å miste kvalitet i simuleringen. 
% %	% 		Dette kan sees i plotta som sammenligner depol-kurve for de to ANN (sjå plott[_ref_])
% %	
% %	Konkluder med å diskutere lettheten i implementasjon(at KANN er vanskeligare å implementere, men med andre pluss..) 			ELLER:   i 'discussion and conclusion' ?
% 
% %%\section{Forskjell i implementasjon}
% %Skrive at forskjellen mellom gamle og nye varianten av 3.gen. ANN (SANN) har mykje til felles med forskjellane mellom Moore vs. Mealy Auromata.
% %
% %Den gamle varianten er for så vidt den som er mest intuitiv å implementere / designe. Denne ser på umiddelbar tilstand (depol. verdi) for nodene. Dersom denne depol. kommer over terskel vil noden gi output til alle sine utnoder.
% %Dette er en direkte simulering av det biologiske neuronet. Kan beskrives (direkte?) med Moore Automata.
% %
% %For den foreslåtte varianten vil Mealy automata beskrive systemet bedre. Her er det 'state' for noden og i tillegg input som gir ut-oppførselen.
% %[skriv kva "utoppførsel" betyr. Alltid samme output (før synapsen) for den Moore-Automata varianten av SANN. For Mealy variant vil output være en flyttallsvariabel]
% %[skriv kvifor denne tanken kom -- at enkel kraftig prosessor vil være oppmot like effektiv med større flyttalsoperasjoner som ved enkle boolske transmissjoner (tjaneei..)
% %Dersom vi har mulighet er ferre større operasjoner bedre for den serielle CPU enn mange små operasjoner.]
% %
% %[Skriv at implementasjonen viste seg å bli meir omfattende enn først tenkt. Skriv om pEstimatedTaskTime og anna ekstra tidsplanlegging]
% %
% %% TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 





















%XXX Skriv i conclusion:
%Because a network of connected neurons have a large degree of complexity, it is best to start with comparing the depolarization of single nodes.
%For comparison of the two models, we will first compare the depolarization of a single neuron of each model.
%Because a system comprised of a network of neurons have 

%IKKJE TA MED. Er ikkje heilt sikker på kvifor det er slik. Dersom eg skal ha det med, kan eg jobbe med dette når rapporten er ferdig!
%\section{Synaptic Transmission}
%Få heilt klar for deg koleis sammenehenen er mellom K syn.t. og s syn.t. er før dette skrives.
%
%When the comparison between the postsynaptisk depolarization began, it could seem like the equations for synaptic trantmission were wrong. 
%The postsynaptic node of a s\_synapse had a larger value that that of the postsynaptic $\kappa$N in a corresponding $\kappa$ANN circuit.
%After analyzing the result, it was found that the error followed the same principles that were discussed in section \ref{ssecTruncationErrorOfSN}.
%
%The initial testing of the different ANN models use few nodes with a strong connection between them.
%The synaptic connections had a synaptic weight that could make the postsynaptic node go to suprathreshold levels in less then ten transmissions.
%In biological networks and in useful artificial networks, a connection of this size would make the system %XXX XXX DÅRLIG (skriv dette på bedre måte..)
%
%The result of this was that the initial transmission of a SN would cause a jump to this level, and the 
% % TODO dersom eg skal skrive denne secion, så må eg legge ved plot:  ../FDP_ANN/datafiles_for_evaluation/sammenligningEtterSynapseMedKonstantPresynSensorFunk.eps !
%When the circuits were initially









%Forenklinger:
%	- Synapsen ser bort fra tidsfenomener (f.eks. potentiation). Skriv at dette er det få som har med.
%
% Skriv også om ting er har med, som ofte er forenkla vekk:
% 	- Tidsdelay i synapse, dendrite, axon.
% 	- Mulighet for å utvide axon og dendrite dersom eg ønsker bedre spatial resolution.
% 	- samme for temporal resolution.
% 	- Implementert det-derre-prinsippet (Dale 's(?)) . Neir ikkje heilt. Har ikkje gjort dette for heile neuron, men enkeltsynapsene er enten E eller I. Dette er vanlig å ikkje ha med.
% 	- I fremtidig arbeid: Tenker å lage ulike synaptisk plastisitetsregler. Muligheten for dette er open..
% 	-
%









%	\subsubsection{Propagation of $\kappa$}
%	%Skriv at det er vanskelig å vite når kappa skal propagere. Skriv litt rundt dette: kva som er intuitivt (ved fyring), beste er å ha transient overføringsfunk men dette krever transferfunk. fokus, 
%	%umulig å vite kva som gir godt nok resultat, så bør gjøre dette eksperimentellt. : sammenligne depol.-forløp, og sjå når de ikkje lenger er lik. Kanskje etter en ekstra periode, lenger tid, anna? 
%	% 	Skal ivertfall vente ei stund. Resultatet om KANN er meir effektivt er avhengig av svaret på dette spm.
%	% KANSKJE DETTE IKKJE SKAL STÅ HER? VEIT IKKKJE KOR..
%	%ELLER: kan skrive resultatet her, etter at eg har sammenligna resultata..
%	For $\kappa$ANN it is hard to know when the activity variable, $\kappa$ should propagate. In many ways, $\kappa$ gives the general input of a node.
%	$\kappa_{ij}$, node $j$\,s influence on node $i$ is given by the period of node $j$, given by $\kappa_j$. 
%	It is wery hard to decide some specific time instance $\kappa_j$ should propagate, since the period when $\kappa_j$ is changed also influences $\kappa_i$. 
%	The period of neuron $j$ and thus the period between synaptic transmissions to neuron $i$ can also be said to be given by the new $\kappa_j$ first after the first period with the new $\kappa_j$.
%	
%	The best is to make a transfer function from $\kappa_j$ to $\kappa_i$ with a transient time course. 
%	Due to time limitations, this will unfortunately be outside the scope of this project, since this will further alter the postsynaptic nodes after node $j$. 
%	A neural network of transfer functions, where each node represents a transform, will probably give a better result both in terms of efficiancy and in terms of the transient time course of each node.
%	
%	What can be established from the above discussion is that the time of propagation should be somewhere between zero and two periods after updating $\kappa$, depending on when $\kappa$ is updated in the period.
%	Because of the caotic and unpredictable nature of neural networks, and the simplification to decide some constant time delay, the time delay between updating $\kappa$ and propagation of $\kappa$ have to be found experimentally.
%	As the effectivity of $\kappa$ANN is strongly dependent on this aspect, it is wery hard to theoretically find the efficiancy of the new model.
%
%	To experimentally find when $\kappa$ propagates, the transient time course of each neuron have to be compared.
%	For pragmatic ANNs, it is also hard to find a measure of ``good enough'' for the comparison of the two plots. 
%	SKRIV MEIR NÅR RESULTAT DUKKER OPP! %TODO
%	%TODO Når eg har sammenligna de to, skriv meir her. Bra nok kan være "rett" output for ut--noden, eller "rett" transient time course for ut-noden, osv. Sammenligner heile tida med den andre modellen som om den var rett.
%	% Dette kan også være feil. Kven veit.. Mykje å skrive på diskursjon etter dette aspektet!






% xxx skrive at det er bra med tidsinvariant overføring: Bl.a. kappa kan når som helst bli rekalkulert. Dersom ligninger for det blir utvikla, kan også kanskje v_0 bli rekalulert?

% XXX CONCLUSION : Eg har funnet at det er veldig bra å bruke Kappa som mål på aktivitetsnivå til neuronet. Dette kan være nyttig for neuroscience..

% XXX CONKLUSJON : skrive at modene i SANN (etablerte modellen) er en Moore variant av det biologiske neuronet. KANN er en Mealy automata av neuronet, noke som gir andre muligheter. Drøft.

% XXX CONKLUSJON : For fANN brukes gjennomsnittsfrekvens over time step. For KANN brukes estimert frekvens for å gi syn. trans.
% 					I denne oppgaven var det ikkje fokus, men dersom en bedre oppførsel ønskes, kan vi la estimerting av frekvens (for syn.trans.) være basert på metoder lært i kyb.
% 					Høgere ordens estimasjon vil nok heilt sikkert gi bedre oppførsel. No er overføringa basert på en naiv estimering av fyringsfrekvens.

% XXX SKRIV OM planning of other tasks: (Teksten er med i resultat-og-diskurs: "comparison of the individual elements" : "The mechnisms of the auron element")
% 	As this implementation have been based on the SANN model, the \emph{K\_axon} also makes use of the \emph{doTask()} function.
%	The alternative way of planning synaptic transmission and other planned tasks first became clear to the author durin the writing of this report, these aspects have not been implemented.
%	As the principle of task planning has been used for the auron element, and can easily be extended to be used for other elements, this is included in the discussion.
%	%The reasoning is sound, and the concept of estimated task time can easily be extended to synapses and other elements. Due to time constraints, this is unfortunately not implemented.


% 	xxx Skriv grunnen til at eg ikkje har nokon uventede resultater: at dette i all hovedsak har vert en utviklingsprosess, og alle uventede resultater har blitt ordnet på undervegs.
% 		Eksemper på slike er den lange diskusjonen tidligere, om avviket mellom K_auron og s_auron. Dette ble fikset. Mye tid har dermed blitt brukt på dette prosjektet.

% 	TODO TODO Poengter at synaptic transmission matematikk er basert på 2.gen. ANN (mens mykje anna er basert på 3.g). Dette kan diskuteres frem og tilbake!


%TODO : Skriv at selv om vi ikkje har fått tid til å kjøre effektivitetssammenligning, så har vi funnet eit viktig resultat. KN kan brukes til å oversette mellom 2.gen og 3.gen ANN.
% 		TODO Finn ut korleis 1.gen funker, og skriv evt. inn dette også. (sjå % ref_123@i_KANN i implementasjon_KANN.tex) EVT ikkje nevn "each of the other generation ANN" og "first gen. ANN" fra linja "% ref_123@i_KANN" står på.

% Kva er nytt i denne oppgaven:
% 	- time planning: kanskje KANN modellen er mindre effektiv, men elementet med time planning kan brukes for SANN også. Da slepper vi å simulere time delay.
% 		Axon blir dermed unødvendige, og vi kan lage eit scheme som bruker tidsplanlegging for forskjellige tasks. FUNKER FOR BEGGE MODELLER!
%
%


% Videre arbeid:
% 	- Lage syn. p.
% 	- Innføre dynamisk teskel (bedre modell for refraction time)
% 	- Foreta effektivitetsanalyse.
% 	- Lage transduction mellom KN og SN. Også mellom fN og KN. Kanskje heile veien, mellom alle generasjoner ANN.
% 	- Utvikle KANN for seg selv. Slik at dette blir så effektivt som mulig..
% 	- single compartment implemention of multiple compartment model of the neuron. (KANN, time scheduling, planlegging av tasks)
% 	- effektivitetsanalyse av dette.
%
%



% Oppsummering (conclution):
% 	innlede med kva som er  gjordt i dette prosjektet (gå gjennom kapittela og skriv ned..)
% 	- Skriv om transduction mellom ANN av ulike generasjoner. Kan bruke KANN til dette! (sjå sec \subsection{The Activity Variable} ).
% 	- Skriv at eg har gjordt den tidsvariante responsen til en overføring (at overføring skjer/ikkje skjer er avhengig av verdi før overføring. Dette skaper eit system som er avhengig av input-historie og tid(lekkasje).
% 		Om til: å ikkje lenger være tidsvariant. Kappa er på en måte tatt utafor tid. Kappa som overført variabel er ikkje tidsvariant, ikkje variant med andre variabler.
% 		=> Den tar vekk ulineariteten innført fra mekanismen: fyring!
%


% Feil/Mangler i denne sammenligninga:
% 	- Har ikkje sett på nettverkseffekta av tidspunkt for propagering av Kappa. Kan bli veldig rart at den propagerer "med en gang" (etter 'current' time iteration).
% 		%TODO analyser dette i diskurs!
% 	- Burde kanskje brukt meir tid på rapporten.
%
%
%
%
%

%%
%%XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
%Skrive at design av/teorien bak  de to impelmentasjonene er så forsjellig at det er vanskelig å sammenligne de to med testing. En enkel kjøring vil ha statisk input (ikkje-endrende input).
%Mealy varianten av SANN (KANN) er spesialisert for ANN med dynamisk (endrende) input. Vil gi eit vanskeligere testoppsett for sammenligning av de to. Lett å implementere for KANN, vanskeligere å implementere for SANN.
%(Da må eg ha egene sensor-neuron som er spesiallaga for å sense en slik dynamisk state).
%%XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
%



