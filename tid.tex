
\section{Time}

Following the fact that the ANN will be simulated asynchronous, the computer resources will deside the size of the time iterations. The maximum size is desided by the real--time requirement of the task.

To make the software general, the simulated time should therefore be unconnected to the world time outside the simulation. To achieve this, a scheduler has been devised for my simulation.


In object oriented programming languages, we can make a linked list of elements. 
If the data of the elements are pointers, the pointers can be pointers to any kind of data. Let the list be of type \emph{$std::list<father*> LIST$} and \emph{$father$} contain virtual fuctions. 

When it is time for the scheduler-thread to start a new task, it calls \emph{LIST.front()$\rightarrow$doTask()}. 
Since \emph{doTask()} is overloaded in the derived classes, we can have different tasks assigned to each class derived from \emph{$<father>$}.




If we have a list of scheduled tasks $L = [a, b, c, T]$, all tasks derived from a common \emph{$<father>$}. 
All tasks can generate new tasks according to the rules of the derived classes, and when a task is done it will be removed from the list.

If we allways pick the first task, the next task to be executed will be task $a$. %All tasks can possibly generate new tasks.
If a generates new tasks $x_{a_1}$, this new task will be added at the end of the list.

\begin{equation}
	L = [b, c, T, x_{a_1}]
\end{equation}

Lets say that $b$ does not generate any new tasks and $c$ gives us two new tasks $[x_{c_1}, x_{c_2}]$, we get the list:
\begin{equation}
	L = [T, x_{a_1}, x_{c_1}, x_{c_2} ]
\end{equation}

As the syntax implies, the element $T$ is a rather unique task. $T$ is a const--instance of the timeIterator--class.


\emph{Skrevet dårlig herretter. Skrevet seint på kvelden:} %XXX XXX

\emph{T$\rightarrow$ doTask()} will have the responsibility for any tasks that have anything with time to do. 

First, it will the iterate the global time variable \emph{unsigned long timeIterations}.

Finally it will append a \emph{self--pointer} to the end of the task list.
\begin{equation}
	L = [x_{a_1}, x_{c_1}, x_{c_2}, T ]
\end{equation}


\subsection{Litt om effektivisering}
Skriv om at det er veldig vanskelig å forutse kva som vil være effektivt. Ulike hardware aritekturer gir  ulikt resultat. Dette er grunn til at eg bare teller antall operasjone. Dersom van lager spesial-hw, så vil det det er spesialisert for gå fort og anna gå seinare..

Skriv også om generellt optimalisering:
\begin{itemize}
	\item flytande tid. Ikkje alle noder trengs å sjekkes kvar iterasjon. (sjå/edit det over).
	\item samle opp beregning av $\kappa$ til slutt. $\kappa$ kan endre seg fleire ganger i løpet av en iterasjon. På grunn av dette skal alle noder som får endra aktivitetsnivå legges inn i ei liste. Denne lista gåes gjennom ved tidsiterasjon (i tid::doTask() ). Skal bare ligge eit element av eit objekt i lista, så dersom $\kappa_i$ endres fleire ganger for neuron $i$, vil det bare bli en kalkulering av depol./`interspike period' per [neuron, tidsiterasjon].
\end{itemize}

Her kan også ``Firing Cycle'' stå. Dette er estimering fordi hastighet ikkje er konstant lik gjennomsnittshastighet. Dersom FC skal brukes (som optimalisering) så kan enten gjennomsnittshastigheta over heile perioden brukes, eller så kan perioden deles opp i $n$, og gjennomsnittet i kvar bit brukes (for eksempel $n=2$: deler farta inn i to deler. Først er farta stor, så blir den mindre, fordi $(1-e^{-at}$ flater ut..)
